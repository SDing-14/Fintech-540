{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-market-calendars in /opt/homebrew/lib/python3.11/site-packages (4.3.1)\n",
      "Requirement already satisfied: pandas>=1.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas-market-calendars) (2.1.3)\n",
      "Requirement already satisfied: pytz in /opt/homebrew/lib/python3.11/site-packages (from pandas-market-calendars) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil in /Users/xinyangding/Library/Python/3.11/lib/python/site-packages (from pandas-market-calendars) (2.8.2)\n",
      "Requirement already satisfied: exchange-calendars>=3.3 in /opt/homebrew/lib/python3.11/site-packages (from pandas-market-calendars) (4.5)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from exchange-calendars>=3.3->pandas-market-calendars) (1.26.2)\n",
      "Requirement already satisfied: pyluach in /opt/homebrew/lib/python3.11/site-packages (from exchange-calendars>=3.3->pandas-market-calendars) (2.2.0)\n",
      "Requirement already satisfied: toolz in /opt/homebrew/lib/python3.11/site-packages (from exchange-calendars>=3.3->pandas-market-calendars) (0.12.0)\n",
      "Requirement already satisfied: tzdata in /opt/homebrew/lib/python3.11/site-packages (from exchange-calendars>=3.3->pandas-market-calendars) (2023.3)\n",
      "Requirement already satisfied: korean-lunar-calendar in /opt/homebrew/lib/python3.11/site-packages (from exchange-calendars>=3.3->pandas-market-calendars) (0.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/xinyangding/Library/Python/3.11/lib/python/site-packages (from python-dateutil->pandas-market-calendars) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/opt/homebrew/opt/python@3.11/bin/python3.11\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas-market-calendars\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_market_calendars as mcal\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform preprocessing for data under various categories.\n",
    "1. Assets that are traded both during and after trading hours\n",
    "    - Cryptocurrencies: Bitcoin\n",
    "    - Commodities & Futures: Oil\n",
    "    \n",
    "Topics:\n",
    "    - Log return\n",
    "    - Bid-ask spread\n",
    "    - Date and time filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19197, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Engineering\n",
    "\n",
    "#1. Percentage change\n",
    "BIT_USD = pd.read_excel('Data/BIT_USD.xlsx', index_col=0)\n",
    "BIT_USD = BIT_USD.iloc[::-1]\n",
    "\n",
    "BIT_USD['BTC_Log_Change'] = np.log(BIT_USD['Open'] / BIT_USD['Open'].shift(1))\n",
    "\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "BIT_USD['BTC_Bid_ask_spread'] = BIT_USD['Ask'] - BIT_USD['Bid']\n",
    "\n",
    "BIT_USD\n",
    "\n",
    "BIT_USD.index = pd.to_datetime(BIT_USD.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "BIT_USD_filtered = BIT_USD[BIT_USD.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "BIT_USD_filtered = BIT_USD_filtered.between_time('09:30:00', '16:00:00')\n",
    "\n",
    "BIT_USD_filtered\n",
    "BIT_USD_filtered.to_csv('Filtered_Data/BIT_USD_filtered.csv')\n",
    "BIT_USD_filtered.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18944, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OIL = pd.read_excel('Data/OIL Price.xlsx', index_col=0)\n",
    "OIL = OIL.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. log return\n",
    "OIL['OIL_Log_Change'] = np.log(OIL['Close'] / OIL['Close'].shift(1))\n",
    "#2. Volume\n",
    "OIL['OIL_Volume'] = OIL['Volume']\n",
    "#3. Bid-Ask Spread\n",
    "OIL['OIL_High_Low_Spread'] = OIL['Ask'] - OIL['Bid']\n",
    "\n",
    "OIL = OIL.between_time('09:30:00', '16:00:00')\n",
    "\n",
    "OIL.index = pd.to_datetime(OIL.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "OIL = OIL[OIL.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "\n",
    "OIL.to_csv('Filtered_Data/OIL_filtered.csv')\n",
    "OIL.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done Commidities & Crypto Currencies####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Equity\n",
    "    - Stock data from over 20 tech companies, taking reference from NASDAQ Tech 100 index. \n",
    "-- Topics:\n",
    "    - Log return\n",
    "    - Bid-ask spread\n",
    "    - Moving average\n",
    "    - RSI\n",
    "    - Date and time filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 19\n"
     ]
    }
   ],
   "source": [
    "AAPL = pd.read_excel('Data/AAPL.xlsx', index_col=0)\n",
    "AAPL.index = pd.to_datetime(AAPL.index)\n",
    "AAPL = AAPL.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "AAPL['AAPL_Log_Change'] = np.log(AAPL['Close'] / AAPL['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "AAPL['AAPL_High_Low_Spread'] = AAPL['High'] - AAPL['Low']\n",
    "AAPL['AAPL_Volume'] = AAPL['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "AAPL['AAPL_1hr_Moving_Average'] = AAPL['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "AAPL['AAPL_RSI'] = calculate_rsi(AAPL['Close'])\n",
    "AAPL['AAPL_Volume'] = AAPL['Volume']\n",
    "\n",
    "#5. Volatility\n",
    "intraday_volatility = AAPL.groupby(AAPL.index.date)['AAPL_Log_Change'].std()\n",
    "AAPL['AAPL_Volatility'] = AAPL.index.normalize().map(intraday_volatility)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AAPL = AAPL.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = AAPL['AAPL_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "\n",
    "\n",
    "AAPL.index = pd.to_datetime(AAPL.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "AAPL_filtered = AAPL[AAPL.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "AAPL_filtered = AAPL_filtered.between_time('09:30:00', '16:00:00')\n",
    "\n",
    "AAPL_filtered\n",
    "AAPL_filtered.to_csv('Filtered_Data/AAPL_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done AAPL####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19197, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN = pd.read_excel('Data/AMZN.xlsx', index_col=0)\n",
    "AMZN.index = pd.to_datetime(AMZN.index)\n",
    "AMZN = AMZN.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "AMZN['AMZN_Log_Change'] = np.log(AMZN['Close'] / AMZN['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "AMZN['AMZN_High_Low_Spread'] = AMZN['High'] - AMZN['Low']\n",
    "AMZN['AMZN_Volume'] = AMZN['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "AMZN['AMZN_1hr_Moving_Average'] = AMZN['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "AMZN['AMZN_RSI'] = calculate_rsi(AMZN['Close'])\n",
    "AMZN['AMZN_Volume'] = AMZN['Volume']\n",
    "\n",
    "intraday_volatility = AMZN.groupby(AMZN.index.date)['AMZN_Log_Change'].std()\n",
    "AMZN['AMZN_Volatility'] = AMZN.index.normalize().map(intraday_volatility)\n",
    "\n",
    "AMZN = AMZN.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = AMZN['AMZN_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "\n",
    "AMZN.index = pd.to_datetime(AMZN.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "AMZN = AMZN[AMZN.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "AMZN = AMZN.between_time('09:30:00', '16:00:00')\n",
    "\n",
    "AMZN.to_csv('Filtered_Data/AMZN_filtered.csv')\n",
    "AMZN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done AMZN####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19197, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOOGL = pd.read_excel('Data/GOOGL.xlsx', index_col=0)\n",
    "GOOGL.index = pd.to_datetime(GOOGL.index)\n",
    "GOOGL = GOOGL.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "GOOGL['GOOGL_Log_Change'] = np.log(GOOGL['Close'] / GOOGL['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "GOOGL['GOOGL_High_Low_Spread'] = GOOGL['High'] - GOOGL['Low']\n",
    "GOOGL['GOOGL_Volume'] = GOOGL['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "GOOGL['GOOGL_1hr_Moving_Average'] = GOOGL['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "GOOGL['GOOGL_RSI'] = calculate_rsi(GOOGL['Close'])\n",
    "GOOGL['GOOGL_Volume'] = GOOGL['Volume']\n",
    "intraday_volatility = GOOGL.groupby(GOOGL.index.date)['GOOGL_Log_Change'].std()\n",
    "GOOGL['GOOGL_Volatility'] = GOOGL.index.normalize().map(intraday_volatility)\n",
    "\n",
    "GOOGL = GOOGL.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = GOOGL['GOOGL_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "GOOGL.index = pd.to_datetime(GOOGL.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "GOOGL = GOOGL[GOOGL.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "GOOGL = GOOGL.between_time('09:30:00', '16:00:00')\n",
    "GOOGL.to_csv('Filtered_Data/GOOGL_filtered.csv')\n",
    "GOOGL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done GOOGL####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19197, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSFT = pd.read_excel('Data/MSFT.xlsx', index_col=0)\n",
    "MSFT.index = pd.to_datetime(MSFT.index)\n",
    "MSFT = MSFT.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "MSFT['MSFT_Log_Change'] = np.log(MSFT['Close'] / MSFT['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "MSFT['MSFT_High_Low_Spread'] = MSFT['High'] - MSFT['Low']\n",
    "MSFT['MSFT_Volume'] = MSFT['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "MSFT['MSFT_1hr_Moving_Average'] = MSFT['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "MSFT['MSFT_RSI'] = calculate_rsi(MSFT['Close'])\n",
    "MSFT['MSFT_Volume'] = MSFT['Volume']\n",
    "\n",
    "intraday_volatility = MSFT.groupby(MSFT.index.date)['MSFT_Log_Change'].std()\n",
    "MSFT['MSFT_Volatility'] = MSFT.index.normalize().map(intraday_volatility)\n",
    "\n",
    "\n",
    "MSFT = MSFT.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = MSFT['MSFT_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "MSFT.index = pd.to_datetime(MSFT.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "MSFT = MSFT[MSFT.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "MSFT.to_csv('Filtered_Data/MSFT_filtered.csv')\n",
    "MSFT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done MSFT####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19197, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSLA = pd.read_excel('Data/TSLA.xlsx', index_col=0)\n",
    "TSLA.index = pd.to_datetime(TSLA.index)\n",
    "TSLA = TSLA.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "TSLA['TSLA_Log_Change'] = np.log(TSLA['Close'] / TSLA['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "TSLA['TSLA_High_Low_Spread'] = TSLA['High'] - TSLA['Low']\n",
    "TSLA['TSLA_Volume'] = TSLA['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "TSLA['TSLA_1hr_Moving_Average'] = TSLA['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "TSLA['TSLA_RSI'] = calculate_rsi(TSLA['Close'])\n",
    "TSLA['TSLA_Volume'] = TSLA['Volume']\n",
    "\n",
    "intraday_volatility = TSLA.groupby(TSLA.index.date)['TSLA_Log_Change'].std()\n",
    "TSLA['TSLA_Volatility'] = TSLA.index.normalize().map(intraday_volatility)\n",
    "\n",
    "TSLA = TSLA.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = TSLA['TSLA_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "TSLA.index = pd.to_datetime(TSLA.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "TSLA = TSLA[TSLA.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "TSLA.to_csv('Filtered_Data/TSLA_filtered.csv')\n",
    "TSLA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done TSLA####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19197, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NVDA = pd.read_excel('Data/NVDA.xlsx', index_col=0)\n",
    "NVDA.index = pd.to_datetime(NVDA.index)\n",
    "NVDA = NVDA.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "NVDA['NVDA_Log_Change'] = np.log(NVDA['Close'] / NVDA['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "NVDA['NVDA_High_Low_Spread'] = NVDA['High'] - NVDA['Low']\n",
    "NVDA['NVDA_Volume'] = NVDA['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "NVDA['NVDA_1hr_Moving_Average'] = NVDA['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "NVDA['NVDA_RSI'] = calculate_rsi(NVDA['Close'])\n",
    "NVDA['NVDA_Volume'] = NVDA['Volume']\n",
    "\n",
    "intraday_volatility = NVDA.groupby(NVDA.index.date)['NVDA_Log_Change'].std()\n",
    "NVDA['NVDA_Volatility'] = NVDA.index.normalize().map(intraday_volatility)\n",
    "\n",
    "NVDA = NVDA.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = NVDA['NVDA_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "NVDA.index = pd.to_datetime(NVDA.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "NVDA = NVDA[NVDA.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "NVDA.to_csv('Filtered_Data/NVDA_filtered.csv')\n",
    "NVDA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done NVDA####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19197, 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "META = pd.read_excel('Data/META.xlsx', index_col=0)\n",
    "META.index = pd.to_datetime(META.index)\n",
    "META = META.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "META['META_Log_Change'] = np.log(META['Close'] / META['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "META['META_High_Low_Spread'] = META['High'] - META['Low']\n",
    "META['META_Volume'] = META['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "META['META_1hr_Moving_Average'] = META['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "META['META_RSI'] = calculate_rsi(META['Close'])\n",
    "META['META_Volume'] = META['Volume']\n",
    "\n",
    "intraday_volatility = META.groupby(META.index.date)['META_Log_Change'].std()\n",
    "META['META_Volatility'] = META.index.normalize().map(intraday_volatility)\n",
    "\n",
    "\n",
    "META = META.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = META['META_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "META.index = pd.to_datetime(META.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "META = META[META.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "META.to_csv('Filtered_Data/META_filtered.csv')\n",
    "META.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done META####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19197, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NFLX = pd.read_excel('Data/NFLX.xlsx', index_col=0)\n",
    "NFLX.index = pd.to_datetime(NFLX.index)\n",
    "NFLX = NFLX.iloc[::-1]\n",
    "\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "NFLX['NFLX_Log_Change'] = np.log(NFLX['Close'] / NFLX['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "NFLX['NFLX_High_Low_Spread'] = NFLX['High'] - NFLX['Low']\n",
    "NFLX['NFLX_Volume'] = NFLX['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "NFLX['NFLX_1hr_Moving_Average'] = NFLX['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "NFLX['NFLX_RSI'] = calculate_rsi(NFLX['Close'])\n",
    "NFLX['NFLX_Volume'] = NFLX['Volume']\n",
    "\n",
    "intraday_volatility = NFLX.groupby(NFLX.index.date)['NFLX_Log_Change'].std()\n",
    "NFLX['NFLX_Volatility'] = NFLX.index.normalize().map(intraday_volatility)\n",
    "\n",
    "NFLX = NFLX.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = NFLX['NFLX_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "NFLX.index = pd.to_datetime(NFLX.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "NFLX = NFLX[NFLX.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "NFLX.to_csv('Filtered_Data/NFLX_filtered.csv')\n",
    "NFLX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done NFLX####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19172, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMCSA = pd.read_excel('Data/CMCSA.xlsx', index_col=0)\n",
    "CMCSA.index = pd.to_datetime(CMCSA.index)\n",
    "CMCSA = CMCSA.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "CMCSA['CMCSA_Log_Change'] = np.log(CMCSA['Close'] / CMCSA['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "CMCSA['CMCSA_High_Low_Spread'] = CMCSA['High'] - CMCSA['Low']\n",
    "CMCSA['CMCSA_Volume'] = CMCSA['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "CMCSA['CMCSA_1hr_Moving_Average'] = CMCSA['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "CMCSA['CMCSA_RSI'] = calculate_rsi(CMCSA['Close'])\n",
    "CMCSA['CMCSA_Volume'] = CMCSA['Volume']\n",
    "\n",
    "intraday_volatility = CMCSA.groupby(CMCSA.index.date)['CMCSA_Log_Change'].std()\n",
    "CMCSA['CMCSA_Volatility'] = CMCSA.index.normalize().map(intraday_volatility)\n",
    "\n",
    "CMCSA = CMCSA.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = CMCSA['CMCSA_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "CMCSA.index = pd.to_datetime(CMCSA.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "CMCSA = CMCSA[CMCSA.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "CMCSA.to_csv('Filtered_Data/CMCSA_filtered.csv')\n",
    "CMCSA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done CMCSA####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19163, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMUS = pd.read_excel('Data/TMUS.xlsx', index_col=0)\n",
    "TMUS.index = pd.to_datetime(TMUS.index)\n",
    "TMUS = TMUS.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "TMUS['TMUS_Log_Change'] = np.log(TMUS['Close'] / TMUS['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "TMUS['TMUS_High_Low_Spread'] = TMUS['High'] - TMUS['Low']\n",
    "TMUS['TMUS_Volume'] = TMUS['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "TMUS['TMUS_1hr_Moving_Average'] = TMUS['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "TMUS['TMUS_RSI'] = calculate_rsi(TMUS['Close'])\n",
    "TMUS['TMUS_Volume'] = TMUS['Volume']\n",
    "\n",
    "intraday_volatility = TMUS.groupby(TMUS.index.date)['TMUS_Log_Change'].std()\n",
    "TMUS['TMUS_Volatility'] = TMUS.index.normalize().map(intraday_volatility)\n",
    "\n",
    "TMUS = TMUS.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = TMUS['TMUS_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "TMUS.index = pd.to_datetime(TMUS.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "TMUS = TMUS[TMUS.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "TMUS.to_csv('Filtered_Data/TMUS_filtered.csv')\n",
    "TMUS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done TMUS####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19189, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QCOM = pd.read_excel('Data/QCOM.xlsx', index_col=0)\n",
    "QCOM.index = pd.to_datetime(QCOM.index)\n",
    "QCOM = QCOM.iloc[::-1]\n",
    "\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "QCOM['QCOM_Log_Change'] = np.log(QCOM['Close'] / QCOM['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "QCOM['QCOM_High_Low_Spread'] = QCOM['High'] - QCOM['Low']\n",
    "QCOM['QCOM_Volume'] = QCOM['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "QCOM['QCOM_1hr_Moving_Average'] = QCOM['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "QCOM['QCOM_RSI'] = calculate_rsi(QCOM['Close'])\n",
    "QCOM['QCOM_Volume'] = QCOM['Volume']\n",
    "\n",
    "intraday_volatility = QCOM.groupby(QCOM.index.date)['QCOM_Log_Change'].std()\n",
    "QCOM['QCOM_Volatility'] = QCOM.index.normalize().map(intraday_volatility)\n",
    "\n",
    "QCOM = QCOM.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = QCOM['QCOM_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "QCOM.index = pd.to_datetime(QCOM.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "QCOM = QCOM[QCOM.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "QCOM.to_csv('Filtered_Data/QCOM_filtered.csv')\n",
    "QCOM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done QCOM####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19160, 14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TXN = pd.read_excel('Data/TXN.xlsx', index_col=0)\n",
    "TXN.index = pd.to_datetime(TXN.index)\n",
    "TXN = TXN.iloc[::-1]\n",
    "\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "TXN['TXN_Log_Change'] = np.log(TXN['Close'] / TXN['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "TXN['TXN_High_Low_Spread'] = TXN['High'] - TXN['Low']\n",
    "TXN['TXN_Volume'] = TXN['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "TXN['TXN_1hr_Moving_Average'] = TXN['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "TXN['TXN_RSI'] = calculate_rsi(TXN['Close'])\n",
    "TXN['TXN_Volume'] = TXN['Volume']\n",
    "\n",
    "intraday_volatility = TXN.groupby(TXN.index.date)['TXN_Log_Change'].std()\n",
    "TXN['TXN_Volatility'] = TXN.index.normalize().map(intraday_volatility)\n",
    "\n",
    "TXN = TXN.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = TXN['TXN_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "TXN.index = pd.to_datetime(TXN.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "TXN = TXN[TXN.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "TXN.to_csv('Filtered_Data/TXN_filtered.csv')\n",
    "TXN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done TXN####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19184, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADBE = pd.read_excel('Data/ADBE.xlsx', index_col=0)\n",
    "ADBE.index = pd.to_datetime(ADBE.index)\n",
    "ADBE = ADBE.iloc[::-1]\n",
    "\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "ADBE['ADBE_Log_Change'] = np.log(ADBE['Close'] / ADBE['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "ADBE['ADBE_High_Low_Spread'] = ADBE['High'] - ADBE['Low']\n",
    "ADBE['ADBE_Volume'] = ADBE['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "ADBE['ADBE_1hr_Moving_Average'] = ADBE['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "ADBE['ADBE_RSI'] = calculate_rsi(ADBE['Close'])\n",
    "ADBE['ADBE_Volume'] = ADBE['Volume']\n",
    "\n",
    "intraday_volatility = ADBE.groupby(ADBE.index.date)['ADBE_Log_Change'].std()\n",
    "ADBE['ADBE_Volatility'] = ADBE.index.normalize().map(intraday_volatility)\n",
    "\n",
    "ADBE = ADBE.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = ADBE['ADBE_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "ADBE.index = pd.to_datetime(ADBE.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "ADBE = ADBE[ADBE.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "ADBE.to_csv('Filtered_Data/ADBE_filtered.csv')\n",
    "ADBE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done ADBE####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19195, 14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COST = pd.read_excel('Data/COST.xlsx', index_col=0)\n",
    "COST.index = pd.to_datetime(COST.index)\n",
    "COST = COST.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "COST['COST_Log_Change'] = np.log(COST['Close'] / COST['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "COST['COST_High_Low_Spread'] = COST['High'] - COST['Low']\n",
    "COST['COST_Volume'] = COST['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "COST['COST_1hr_Moving_Average'] = COST['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "COST['COST_RSI'] = calculate_rsi(COST['Close'])\n",
    "COST['COST_Volume'] = COST['Volume']\n",
    "\n",
    "intraday_volatility = COST.groupby(COST.index.date)['COST_Log_Change'].std()\n",
    "COST['COST_Volatility'] = COST.index.normalize().map(intraday_volatility)\n",
    "\n",
    "COST = COST.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = COST['COST_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "COST.index = pd.to_datetime(COST.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "COST = COST[COST.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "COST.to_csv('Filtered_Data/COST_filtered.csv')\n",
    "COST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done COST####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19182, 14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMAT = pd.read_excel('Data/AMAT.xlsx', index_col=0)\n",
    "AMAT.index = pd.to_datetime(AMAT.index)\n",
    "AMAT = AMAT.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "AMAT['AMAT_Log_Change'] = np.log(AMAT['Close'] / AMAT['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "AMAT['AMAT_High_Low_Spread'] = AMAT['High'] - AMAT['Low']\n",
    "AMAT['AMAT_Volume'] = AMAT['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "AMAT['AMAT_1hr_Moving_Average'] = AMAT['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "AMAT['AMAT_RSI'] = calculate_rsi(AMAT['Close'])\n",
    "AMAT['AMAT_Volume'] = AMAT['Volume']\n",
    "\n",
    "intraday_volatility = AMAT.groupby(AMAT.index.date)['AMAT_Log_Change'].std()\n",
    "AMAT['AMAT_Volatility'] = AMAT.index.normalize().map(intraday_volatility)\n",
    "\n",
    "AMAT = AMAT.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = AMAT['AMAT_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "AMAT.index = pd.to_datetime(AMAT.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "AMAT = AMAT[AMAT.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "AMAT.to_csv('Filtered_Data/AMAT_filtered.csv')\n",
    "AMAT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done AMAT####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19183, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PEP = pd.read_excel('Data/PEP.xlsx', index_col=0)\n",
    "PEP.index = pd.to_datetime(PEP.index)\n",
    "PEP = PEP.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "PEP['PEP_Log_Change'] = np.log(PEP['Close'] / PEP['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "PEP['PEP_High_Low_Spread'] = PEP['High'] - PEP['Low']\n",
    "PEP['PEP_Volume'] = PEP['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "PEP['PEP_1hr_Moving_Average'] = PEP['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "PEP['PEP_RSI'] = calculate_rsi(PEP['Close'])\n",
    "PEP['PEP_Volume'] = PEP['Volume']\n",
    "\n",
    "intraday_volatility = PEP.groupby(PEP.index.date)['PEP_Log_Change'].std()\n",
    "PEP['PEP_Volatility'] = PEP.index.normalize().map(intraday_volatility)\n",
    "\n",
    "PEP = PEP.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = PEP['PEP_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "PEP.index = pd.to_datetime(PEP.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "PEP = PEP[PEP.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "PEP.to_csv('Filtered_Data/PEP_filtered.csv')\n",
    "PEP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done PEP####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19158, 14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HON = pd.read_excel('Data/HON.xlsx', index_col=0)\n",
    "HON.index = pd.to_datetime(HON.index)\n",
    "HON = HON.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "HON['HON_Log_Change'] = np.log(HON['Close'] / HON['Close'].shift(1))\n",
    "\n",
    "#2. Bid-Ask Spread\n",
    "HON['HON_High_Low_Spread'] = HON['High'] - HON['Low']\n",
    "HON['HON_Volume'] = HON['Volume']\n",
    "\n",
    "#3. Moving Average\n",
    "HON['HON_1hr_Moving_Average'] = HON['Open'].rolling(window=20).mean()\n",
    "\n",
    "#4. RSI\n",
    "def calculate_rsi(data, window=20):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    RS = gain / loss\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "HON['HON_RSI'] = calculate_rsi(HON['Close'])\n",
    "HON['HON_Volume'] = HON['Volume']\n",
    "\n",
    "intraday_volatility = HON.groupby(HON.index.date)['HON_Log_Change'].std()\n",
    "HON['HON_Volatility'] = HON.index.normalize().map(intraday_volatility)\n",
    "\n",
    "HON = HON.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = HON['HON_RSI'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "HON.index = pd.to_datetime(HON.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "HON = HON[HON.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "HON.to_csv('Filtered_Data/HON_filtered.csv')\n",
    "HON.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done HON####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done Stock Preprocessing####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Index Preprocessing\n",
    "    - Market index (NASDAQ)\n",
    "    - Industry index (ARCA_Tech)\n",
    "-- Topic:\n",
    "    - Log change\n",
    "    - Moving average\n",
    "    - Date and Time filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19127, 9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARCA_TECH = pd.read_excel('Data/ARCA_TECH.xlsx', index_col=0)\n",
    "ARCA_TECH.index = pd.to_datetime(ARCA_TECH.index)\n",
    "ARCA_TECH = ARCA_TECH.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "ARCA_TECH['ARCA_TECH_Log_Change'] = np.log(ARCA_TECH['Close'] / ARCA_TECH['Close'].shift(1))\n",
    "\n",
    "#2. Moving Average\n",
    "ARCA_TECH['ARCA_TECH_1hr_Moving_Average'] = ARCA_TECH['Close'].rolling(window=20).mean()\n",
    "\n",
    "ARCA_TECH = ARCA_TECH.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = ARCA_TECH['ARCA_TECH_1hr_Moving_Average'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "\n",
    "ARCA_TECH.index = pd.to_datetime(ARCA_TECH.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "ARCA_TECH = ARCA_TECH[ARCA_TECH.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "missing_dates = ARCA_TECH[ARCA_TECH.index.time == pd.to_datetime('09:35:00').time()].index.date\n",
    "\n",
    "new_data = []\n",
    "for date in missing_dates:\n",
    "    data_0935 = ARCA_TECH.loc[ARCA_TECH.index == pd.Timestamp(f'{date} 09:35:00')]\n",
    "\n",
    "    data_0930 = data_0935.copy()\n",
    "    data_0930.index = pd.to_datetime([f'{date} 09:30:00'])\n",
    "\n",
    "    new_data.append(data_0930)\n",
    "new_data_df = pd.concat(new_data)\n",
    "\n",
    "ARCA_TECH = pd.concat([ARCA_TECH, new_data_df]).sort_index()\n",
    "\n",
    "ARCA_TECH.to_csv('Filtered_Data/ARCA_TECH_filtered.csv')\n",
    "ARCA_TECH.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done Index Preprocessing####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ColumnName': 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19078, 11)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NASDAQ = pd.read_excel('Data/NASDAQ.xlsx', index_col=0)\n",
    "NASDAQ.index = pd.to_datetime(NASDAQ.index)\n",
    "NASDAQ = NASDAQ.iloc[::-1]\n",
    "#Feature Engineering\n",
    "#1. Log Change\n",
    "NASDAQ['NASDAQ_Log_Change'] = np.log(ARCA_TECH['Close'] / ARCA_TECH['Close'].shift(1))\n",
    "\n",
    "#2. Moving Average\n",
    "NASDAQ['NASDAQ_1hr_Moving_Average'] = NASDAQ['Close'].rolling(window=20).mean()\n",
    "\n",
    "NASDAQ = NASDAQ.between_time('09:30:00', '16:00:00')\n",
    "missing_values_count = NASDAQ['NASDAQ_1hr_Moving_Average'].isna().sum()\n",
    "print(f\"Number of missing values in 'ColumnName': {missing_values_count}\")\n",
    "\n",
    "NASDAQ.index = pd.to_datetime(NASDAQ.index)\n",
    "nyse_calendar = mcal.get_calendar('NYSE')\n",
    "\n",
    "intraday_volatility = NASDAQ.groupby(NASDAQ.index.date)['NASDAQ_Log_Change'].std()\n",
    "NASDAQ['NASDAQ_Volatility'] = NASDAQ.index.normalize().map(intraday_volatility)\n",
    "NASDAQ['NASDAQ_Volatility'] = NASDAQ['NASDAQ_Volatility'].shift(-78)\n",
    "\n",
    "start_date = pd.Timestamp('2022-11-21 09:30:00')\n",
    "end_date = pd.Timestamp('2023-11-08 16:00:00')\n",
    "\n",
    "schedule = nyse_calendar.schedule(start_date=start_date, end_date=end_date)\n",
    "NASDAQ = NASDAQ[NASDAQ.index.normalize().isin(schedule.index.date)]\n",
    "\n",
    "missing_dates = NASDAQ[NASDAQ.index.time == pd.to_datetime('09:35:00').time()].index.date\n",
    "\n",
    "new_data = []\n",
    "for date in missing_dates:\n",
    "    data_0935 = NASDAQ.loc[NASDAQ.index == pd.Timestamp(f'{date} 09:35:00')]\n",
    "\n",
    "    data_0930 = data_0935.copy()\n",
    "    data_0930.index = pd.to_datetime([f'{date} 09:30:00'])\n",
    "\n",
    "    new_data.append(data_0930)\n",
    "    \n",
    "new_data_df = pd.concat(new_data)\n",
    "\n",
    "NASDAQ = pd.concat([NASDAQ, new_data_df]).sort_index()\n",
    "\n",
    "NASDAQ.to_csv('Filtered_Data/NASDAQ_filtered.csv')\n",
    "NASDAQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Done Commodities####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex([], dtype='datetime64[ns]', name='Local Date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Convert index to datetime (if not already)\n",
    "AAPL.index = pd.to_datetime(AAPL.index)\n",
    "OIL.index = pd.to_datetime(OIL.index)\n",
    "\n",
    "# Align the date ranges of both datasets\n",
    "start_date = max(AAPL.index.min(), OIL.index.min())\n",
    "end_date = min(AAPL.index.max(), OIL.index.max())\n",
    "AAPL_aligned = AAPL.loc[start_date:end_date]\n",
    "OIL_aligned = OIL.loc[start_date:end_date]\n",
    "\n",
    "# Find timestamps in AAPL that are not in OIL\n",
    "missing_in_AAPL = OIL_aligned.index.difference(AAPL_aligned.index)\n",
    "print(missing_in_AAPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-18</th>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-22</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-23</th>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.094500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>0.065333</td>\n",
       "      <td>0.851333</td>\n",
       "      <td>0.082667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02</th>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.873500</td>\n",
       "      <td>0.065500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-03</th>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.091500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-07</th>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-08</th>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.875857</td>\n",
       "      <td>0.091286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 neg       neu       pos\n",
       "date                                    \n",
       "2022-11-18  0.052000  0.841000  0.107000\n",
       "2022-11-22  0.008000  0.832000  0.160000\n",
       "2022-11-23  0.050500  0.855000  0.094500\n",
       "2022-11-24  0.096000  0.865000  0.039000\n",
       "2022-11-25  0.065333  0.851333  0.082667\n",
       "...              ...       ...       ...\n",
       "2023-11-02  0.061000  0.873500  0.065500\n",
       "2023-11-03  0.061000  0.847500  0.091500\n",
       "2023-11-06  0.062000  0.827500  0.110000\n",
       "2023-11-07  0.006000  0.885000  0.109000\n",
       "2023-11-08  0.033000  0.875857  0.091286\n",
       "\n",
       "[255 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTIMENT = pd.read_csv('sentiment.csv', index_col=0)\n",
    "\n",
    "if not pd.api.types.is_datetime64_any_dtype(SENTIMENT.index):\n",
    "    SENTIMENT.index = pd.to_datetime(SENTIMENT.index)\n",
    "\n",
    "# Sort the DataFrame by the 'Date' in ascending order (oldest dates first)\n",
    "SENTIMENT = SENTIMENT.sort_values(by='date', ascending=True)\n",
    "\n",
    "# Display the first few rows of the sorted DataFrame\n",
    "SENTIMENT\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
