{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "510/510 [==============================] - 1s 661us/step - loss: 0.0084\n",
      "Epoch 2/50\n",
      "510/510 [==============================] - 0s 634us/step - loss: 0.0018\n",
      "Epoch 3/50\n",
      "510/510 [==============================] - 0s 621us/step - loss: 8.6212e-04\n",
      "Epoch 4/50\n",
      "510/510 [==============================] - 0s 612us/step - loss: 3.4111e-04\n",
      "Epoch 5/50\n",
      "510/510 [==============================] - 0s 649us/step - loss: 2.0664e-04\n",
      "Epoch 6/50\n",
      "510/510 [==============================] - 0s 635us/step - loss: 1.5183e-04\n",
      "Epoch 7/50\n",
      "510/510 [==============================] - 0s 624us/step - loss: 1.2606e-04\n",
      "Epoch 8/50\n",
      "510/510 [==============================] - 0s 621us/step - loss: 1.0146e-04\n",
      "Epoch 9/50\n",
      "510/510 [==============================] - 0s 602us/step - loss: 1.0608e-04\n",
      "Epoch 10/50\n",
      "510/510 [==============================] - 0s 605us/step - loss: 1.1403e-04\n",
      "Epoch 11/50\n",
      "510/510 [==============================] - 0s 599us/step - loss: 6.4391e-05\n",
      "Epoch 12/50\n",
      "510/510 [==============================] - 0s 601us/step - loss: 5.9755e-05\n",
      "Epoch 13/50\n",
      "510/510 [==============================] - 0s 604us/step - loss: 2.0942e-05\n",
      "Epoch 14/50\n",
      "510/510 [==============================] - 0s 603us/step - loss: 1.5161e-05\n",
      "Epoch 15/50\n",
      "510/510 [==============================] - 0s 603us/step - loss: 1.4897e-05\n",
      "Epoch 16/50\n",
      "510/510 [==============================] - 0s 607us/step - loss: 2.1482e-05\n",
      "Epoch 17/50\n",
      "510/510 [==============================] - 0s 605us/step - loss: 3.1458e-05\n",
      "Epoch 18/50\n",
      "510/510 [==============================] - 0s 608us/step - loss: 3.0619e-05\n",
      "Epoch 19/50\n",
      "510/510 [==============================] - 0s 613us/step - loss: 1.5916e-05\n",
      "Epoch 20/50\n",
      "510/510 [==============================] - 0s 606us/step - loss: 7.8382e-06\n",
      "Epoch 21/50\n",
      "510/510 [==============================] - 0s 606us/step - loss: 1.3397e-06\n",
      "Epoch 22/50\n",
      "510/510 [==============================] - 0s 657us/step - loss: 1.0349e-06\n",
      "Epoch 23/50\n",
      "510/510 [==============================] - 0s 605us/step - loss: 2.2435e-06\n",
      "Epoch 24/50\n",
      "510/510 [==============================] - 0s 603us/step - loss: 3.1263e-06\n",
      "Epoch 25/50\n",
      "510/510 [==============================] - 0s 605us/step - loss: 2.5707e-06\n",
      "Epoch 26/50\n",
      "510/510 [==============================] - 0s 609us/step - loss: 6.2749e-06\n",
      "Epoch 27/50\n",
      "510/510 [==============================] - 0s 605us/step - loss: 1.5605e-06\n",
      "Epoch 28/50\n",
      "510/510 [==============================] - 0s 607us/step - loss: 3.4591e-07\n",
      "Epoch 29/50\n",
      "510/510 [==============================] - 0s 605us/step - loss: 3.0572e-07\n",
      "Epoch 30/50\n",
      "510/510 [==============================] - 0s 606us/step - loss: 3.1212e-07\n",
      "Epoch 31/50\n",
      "510/510 [==============================] - 0s 611us/step - loss: 3.0541e-07\n",
      "Epoch 32/50\n",
      "510/510 [==============================] - 0s 607us/step - loss: 2.4831e-07\n",
      "Epoch 33/50\n",
      "510/510 [==============================] - 0s 606us/step - loss: 2.5103e-07\n",
      "Epoch 34/50\n",
      "510/510 [==============================] - 0s 609us/step - loss: 2.1666e-07\n",
      "Epoch 35/50\n",
      "510/510 [==============================] - 0s 602us/step - loss: 2.2795e-07\n",
      "Epoch 36/50\n",
      "510/510 [==============================] - 0s 603us/step - loss: 1.9439e-07\n",
      "Epoch 37/50\n",
      "510/510 [==============================] - 0s 602us/step - loss: 1.6092e-07\n",
      "Epoch 38/50\n",
      "510/510 [==============================] - 0s 602us/step - loss: 1.7505e-07\n",
      "Epoch 39/50\n",
      "510/510 [==============================] - 0s 601us/step - loss: 2.0089e-07\n",
      "Epoch 40/50\n",
      "510/510 [==============================] - 0s 618us/step - loss: 1.5677e-07\n",
      "Epoch 41/50\n",
      "510/510 [==============================] - 0s 618us/step - loss: 1.6727e-07\n",
      "Epoch 42/50\n",
      "510/510 [==============================] - 0s 602us/step - loss: 1.9538e-07\n",
      "Epoch 43/50\n",
      "510/510 [==============================] - 0s 604us/step - loss: 2.3077e-07\n",
      "Epoch 44/50\n",
      "510/510 [==============================] - 0s 620us/step - loss: 1.6349e-07\n",
      "Epoch 45/50\n",
      "510/510 [==============================] - 0s 612us/step - loss: 1.3499e-07\n",
      "Epoch 46/50\n",
      "510/510 [==============================] - 0s 611us/step - loss: 1.3686e-07\n",
      "Epoch 47/50\n",
      "510/510 [==============================] - 0s 609us/step - loss: 1.2462e-07\n",
      "Epoch 48/50\n",
      "510/510 [==============================] - 0s 607us/step - loss: 1.1846e-07\n",
      "Epoch 49/50\n",
      "510/510 [==============================] - 0s 609us/step - loss: 1.0930e-07\n",
      "Epoch 50/50\n",
      "510/510 [==============================] - 0s 606us/step - loss: 1.0674e-07\n",
      "90/90 [==============================] - 0s 363us/step\n",
      "R-squared on Test Set: 0.41141848272555104\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "np.random.seed(100)\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "df = pd.read_csv('combined_dataset.csv')\n",
    "\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "df = df.drop(columns=duplicate_columns)\n",
    "\n",
    "# Using 'NASDAQ_Volatility' as the target variable\n",
    "X = df.drop(columns=['NASDAQ_Volatility']).values\n",
    "y = df['NASDAQ_Volatility'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "n_timesteps = 1\n",
    "X_train = X_train.reshape((X_train.shape[0], n_timesteps, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_timesteps, X_test.shape[1]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_timesteps, X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f'R-squared on Test Set: {r_squared}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "510/510 [==============================] - 2s 2ms/step - loss: 2.0246e-05\n",
      "Epoch 2/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 6.5939e-06\n",
      "Epoch 3/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.4318e-05\n",
      "Epoch 4/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 2.1753e-06\n",
      "Epoch 5/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.2150e-05\n",
      "Epoch 6/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 2.1613e-06\n",
      "Epoch 7/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.0081e-06\n",
      "Epoch 8/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 4.1899e-07\n",
      "Epoch 9/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 2.3418e-07\n",
      "Epoch 10/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 2.1104e-07\n",
      "Epoch 11/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 2.1058e-07\n",
      "Epoch 12/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.9563e-07\n",
      "Epoch 13/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.7270e-07\n",
      "Epoch 14/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.6481e-07\n",
      "Epoch 15/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.5421e-07\n",
      "Epoch 16/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.5094e-07\n",
      "Epoch 17/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.4139e-07\n",
      "Epoch 18/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.3164e-07\n",
      "Epoch 19/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.3747e-07\n",
      "Epoch 20/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.2641e-07\n",
      "Epoch 21/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 2.7294e-07\n",
      "Epoch 22/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.3613e-07\n",
      "Epoch 23/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 2.3581e-07\n",
      "Epoch 24/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 1.1031e-07\n",
      "Epoch 25/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 8.6167e-08\n",
      "Epoch 26/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 8.8115e-08\n",
      "Epoch 27/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 8.5755e-08\n",
      "Epoch 28/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 8.1887e-08\n",
      "Epoch 29/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 7.5938e-08\n",
      "Epoch 30/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 7.7203e-08\n",
      "Epoch 31/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 6.9731e-08\n",
      "Epoch 32/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 6.6236e-08\n",
      "Epoch 33/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 6.5640e-08\n",
      "Epoch 34/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 6.1446e-08\n",
      "Epoch 35/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 6.3603e-08\n",
      "Epoch 36/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 5.8090e-08\n",
      "Epoch 37/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 5.4974e-08\n",
      "Epoch 38/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 5.0839e-08\n",
      "Epoch 39/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 5.0708e-08\n",
      "Epoch 40/50\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 5.0099e-08\n",
      "Epoch 41/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 5.0862e-08\n",
      "Epoch 42/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 4.7902e-08\n",
      "Epoch 43/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 4.4322e-08\n",
      "Epoch 44/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 4.5258e-08\n",
      "Epoch 45/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 4.3521e-08\n",
      "Epoch 46/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 4.3838e-08\n",
      "Epoch 47/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 4.4140e-08\n",
      "Epoch 48/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 4.0214e-08\n",
      "Epoch 49/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 3.9451e-08\n",
      "Epoch 50/50\n",
      "510/510 [==============================] - 1s 2ms/step - loss: 4.1688e-08\n",
      "90/90 [==============================] - 0s 603us/step\n",
      "R-squared on Test Set: 0.8063815976879679\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Dropout, Bidirectional\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "df = pd.read_csv('combined_dataset.csv')\n",
    "\n",
    "\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "df = df.drop(columns=duplicate_columns)\n",
    "\n",
    "X = df.drop(columns=['NASDAQ_Volatility']).values\n",
    "y = df['NASDAQ_Volatility'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "n_timesteps = 1 \n",
    "X_train = X_train.reshape((X_train.shape[0], n_timesteps, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_timesteps, X_test.shape[1]))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(50, activation='relu', return_sequences=True), input_shape=(n_timesteps, X_train.shape[2])))\n",
    "\n",
    "model.add(LSTM(38, activation='relu', return_sequences=False))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(30, activation='relu'))\n",
    "\n",
    "model.add(Dense(20, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f'R-squared on Test Set: {r_squared}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
